{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates subsets of a large dataset only based on randomly selecting files up to a user defined maximum size (in GB) in the variable \"max_size\". \n",
    "\n",
    "Source_directory and target_directory are variables that need to be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def get_dataset_size(dataset_dir):\n",
    "    \n",
    "    total_size = 0\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    # Convert total_size to a more human-readable format (e.g., MB, GB)\n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    total_size_gb = total_size / (1024 * 1024 * 1024)\n",
    "\n",
    "    return total_size, total_size_mb, total_size_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset(source_dir, source_folder, target_dir, target_folder, batch_size, max_size):\n",
    "    '''\n",
    "    Creates subset based on a maximum size in GB\n",
    "    \n",
    "    Args:\n",
    "        source_dir, source_folder (~string): path and name of directory from where access to the data. It must contain \n",
    "        images and labels folders containing pre and post images (png format) and info (json format) files respectively.\n",
    "        target_dir, target_folder (~string): path and name of directory where to store new dataset\n",
    "        batch_size (~int): how many images will be randomly selected in each iteration (larger the parameter, less exact the desired size of the subset)\n",
    "        max_size (~float): Maximum desired size in Gb.\n",
    "    '''\n",
    "    total_ids = []\n",
    "    total_size_gb = 0\n",
    "    while total_size_gb <=  max_size:\n",
    "        #list of name files in images and labels directories for the folder specified in \"source_folder\" variable\n",
    "        tif_files = [file for file in os.listdir(source_dir+\"/\"+source_folder+\"/images\") if file.endswith('.png')]\n",
    "        json_files = [file for file in os.listdir(source_dir+\"/\"+source_folder+\"/labels\") if file.endswith('.json')]\n",
    "        \n",
    "        # collecting id number for all the files in \"source_folder\"\n",
    "        ids = list(set([x.rsplit(\"_\")[1] for x in tif_files]))\n",
    "        \n",
    "        # Randomly select a subset of ids\n",
    "        selected_ids = random.sample(ids, batch_size)\n",
    "        \n",
    "        #getting list of files, given certain id number\n",
    "        \n",
    "        # collecting files in images/hold\n",
    "        tif_files_selected = []\n",
    "        for id in selected_ids:\n",
    "            if id not in total_ids:\n",
    "                tif_files_selected.extend(glob.glob(source_dir+\"/\"+source_folder+\"/images/*\"+id+\"*.png\"))\n",
    "        #collecting files in labels/hold\n",
    "        json_files_selected = []\n",
    "        for id in selected_ids:\n",
    "            if id not in total_ids:\n",
    "                json_files_selected.extend(glob.glob(source_dir+\"/\"+source_folder+\"/labels/*\"+id+\"*.json\"))        \n",
    "        \n",
    "        # save ids to not repeat\n",
    "        #print(\"ids in this iteration: \",total_ids)\n",
    "        total_ids.extend(selected_ids)\n",
    "        \n",
    "        # Copy the selected files to the target directory (target_folder/images)\n",
    "        for path in tif_files_selected:\n",
    "            file = path.rsplit(\"/\")[-1]\n",
    "            source_path = os.path.join(source_dir, source_folder,\"images\",file)\n",
    "            target_path = os.path.join(target_dir, target_folder,\"images\", file)\n",
    "            #print(source_path)\n",
    "            #print(target_path)\n",
    "            shutil.copyfile(source_path, target_path)\n",
    "\n",
    "        # Copy the selected files to the target directory (target_folder/labels)\n",
    "        for path in json_files_selected:\n",
    "            file = path.rsplit(\"/\")[-1]\n",
    "            source_path = os.path.join(source_dir, source_folder,\"labels\",file)\n",
    "            target_path = os.path.join(target_dir, target_folder,\"labels\", file)\n",
    "            #print(source_path)\n",
    "            #print(target_path)\n",
    "            shutil.copyfile(source_path, target_path)\n",
    "        total_size, total_size_mb, total_size_gb = get_dataset_size(os.path.join(target_dir, target_folder))   \n",
    "        print(\"current target directory size (GB): \",total_size_gb)\n",
    "        #print(\"the final size (GB) of the target directory \",target_dir,\" is: \",total_size_gb)\n",
    "    print(\"Max. size reached!: \",total_size_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the following, change source_directory and target_directory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_dirs = [\"hold\",\"test\",\"tier1\"] # directories in the source directory from which I want to extract data. tier3 has another dataset with different disasters\n",
    "\n",
    "# Set the paths and parameters for creating the subset \n",
    "source_directory = '../data/last_subset'  # Path to your large dataset directory\n",
    "target_directory = '../data/test_subset'  # Path to the directory where the subset will be created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is divided between training and test in the proportions 0.6 and 0.2 respectively.\n",
    "\n",
    "See below variable \"max_size\" for each folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/test_subset/train/images' already exists.\n",
      "Directory '../data/test_subset/train/labels' already exists.\n",
      "current target directory size (GB):  0.035128360614180565\n",
      "current target directory size (GB):  0.07047110889106989\n",
      "current target directory size (GB):  0.1134218629449606\n",
      "current target directory size (GB):  0.15796535089612007\n",
      "current target directory size (GB):  0.20389750134199858\n",
      "current target directory size (GB):  0.24228623881936073\n",
      "current target directory size (GB):  0.270885176025331\n",
      "current target directory size (GB):  0.31638297718018293\n",
      "current target directory size (GB):  0.3441677941009402\n",
      "current target directory size (GB):  0.38357523549348116\n",
      "current target directory size (GB):  0.40073469653725624\n",
      "current target directory size (GB):  0.48580285627394915\n",
      "current target directory size (GB):  0.5434338822960854\n",
      "current target directory size (GB):  0.6092087794095278\n",
      "current target directory size (GB):  0.6448980998247862\n",
      "current target directory size (GB):  0.68356460519135\n",
      "current target directory size (GB):  0.7354202466085553\n",
      "current target directory size (GB):  0.7627329807728529\n",
      "current target directory size (GB):  0.8069051187485456\n",
      "current target directory size (GB):  0.8515482936054468\n",
      "current target directory size (GB):  0.8807499632239342\n",
      "current target directory size (GB):  0.9309479026123881\n",
      "current target directory size (GB):  0.9743323307484388\n",
      "current target directory size (GB):  1.0023818714544177\n",
      "current target directory size (GB):  1.0300757577642798\n",
      "current target directory size (GB):  1.0833971882238984\n",
      "current target directory size (GB):  1.1440906655043364\n",
      "current target directory size (GB):  1.1621228568255901\n",
      "current target directory size (GB):  1.204142864793539\n",
      "Max. size reached!:  1.204142864793539\n"
     ]
    }
   ],
   "source": [
    "# create TRAINING set\n",
    "\n",
    "source_folder = \"train\"\n",
    "target_folder = \"train\"\n",
    "#images\n",
    "train_images_dir = os.path.join(target_directory, target_folder,\"images\")\n",
    "#print(train_images_dir)\n",
    "#labels\n",
    "train_labels_dir = os.path.join(target_directory, target_folder,\"labels\")\n",
    "# create directories\n",
    "try:\n",
    "    os.makedirs(train_images_dir)\n",
    "    os.makedirs(train_labels_dir)\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{train_images_dir}' already exists.\")    \n",
    "    print(f\"Directory '{train_labels_dir}' already exists.\")  \n",
    "\n",
    "# set parameters training set\n",
    "batch_size=5       # Number of images that are randomly selected in each iteration per folder in \"sub_dirs\" variable\n",
    "max_size = 1.2 #in Gb\n",
    "\n",
    "# Call the function to create the subset TRAINING (tier1 is training in original dataset)\n",
    "create_subset(source_directory, source_folder, target_directory, target_folder, batch_size, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/test_subset/test/images\n",
      "current target directory size (GB):  0.022559155710041523\n",
      "current target directory size (GB):  0.04454149957746267\n",
      "current target directory size (GB):  0.0694432957097888\n",
      "current target directory size (GB):  0.08138161338865757\n",
      "current target directory size (GB):  0.10628349054604769\n",
      "current target directory size (GB):  0.1286655217409134\n",
      "current target directory size (GB):  0.15267665963619947\n",
      "current target directory size (GB):  0.17895563505589962\n",
      "current target directory size (GB):  0.19639226607978344\n",
      "current target directory size (GB):  0.21783117298036814\n",
      "current target directory size (GB):  0.2393433516845107\n",
      "current target directory size (GB):  0.2542531508952379\n",
      "current target directory size (GB):  0.27163968048989773\n",
      "current target directory size (GB):  0.28503435757011175\n",
      "current target directory size (GB):  0.29565922915935516\n",
      "current target directory size (GB):  0.3195598116144538\n",
      "current target directory size (GB):  0.33307626005262136\n",
      "current target directory size (GB):  0.34441658295691013\n",
      "current target directory size (GB):  0.3608191879466176\n",
      "current target directory size (GB):  0.37125604413449764\n",
      "current target directory size (GB):  0.3843463333323598\n",
      "current target directory size (GB):  0.4037663880735636\n",
      "Max. size reached!:  0.4037663880735636\n"
     ]
    }
   ],
   "source": [
    "# create TEST set\n",
    "\n",
    "source_folder = \"test\"\n",
    "target_folder = \"test\"\n",
    "#images\n",
    "train_images_dir = os.path.join(target_directory, target_folder,\"images\")\n",
    "print(train_images_dir)\n",
    "#labels\n",
    "train_labels_dir = os.path.join(target_directory, target_folder,\"labels\")\n",
    "# create directories\n",
    "try:\n",
    "    os.makedirs(train_images_dir)\n",
    "    os.makedirs(train_labels_dir)\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{train_images_dir}' already exists.\")    \n",
    "    print(f\"Directory '{train_labels_dir}' already exists.\") \n",
    "\n",
    "# set parameters training set\n",
    "batch_size=5       # Number of images that are randomly selected in each iteration \n",
    "max_size = 0.4 #in Gb\n",
    "\n",
    "# Call the function to create the subset TRAINING (tier1 is training in original dataset)\n",
    "create_subset(source_directory, source_folder, target_directory, target_folder, batch_size, max_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
