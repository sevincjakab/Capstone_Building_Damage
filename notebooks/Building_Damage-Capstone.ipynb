{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Subset Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -->Helper Code from Previous Noteboooks Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part2 and part3\n",
    "- uses shell commands to prepare the data in a way that it can be loaded into tensorflow, \n",
    "- split our data into a train and validation set (can be skipped if data are in separate folders)\n",
    "- loads the data\n",
    "- defines some functions that will allow us to directly import our pictures and the corresponding class labels \n",
    "- defines functions for data augmentation (Note: Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It is done to prevent overfitting).It includes making minor changes to the dataset or using deep learning to generate new data points.)\n",
    "- defines a function to automatically add other functions to a python file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how the codes are adjusted from Image_Modeling Notebook1 and Notebook2:\n",
    "\n",
    "- `flowers_train.csv` replaced with `buildings_train.csv`\n",
    "- `flowers_eval.csv` replaced with `buildings_validation.csv`\n",
    "- `flowers_test.csv` replaced with `buildings_test.csv`\n",
    "- `Image_Modeling.py` replaced with `Building_Damage-Python.py`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--!Check what the following cell does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any file that gets constructed by the notebook.\n",
    "!rm -f Building_Damage-Python.py buildings_train.csv buildings_validation.csv buildings_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code helps us to register the consecutive cells automatically into a\n",
    "# python script whenever we put %%write_and_run Building_Damage-Python.py at the \n",
    "# beginning of that cell\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    \"\"\"write python code into file and execute it as well\"\"\"\n",
    "\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "        print(\"Appended to file \", file)\n",
    "    else:\n",
    "        print('Written to file:', file)\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell.format(**globals()))        \n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#load more libraries here if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tensorflow version and set verbosity\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(v=tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data ?\n",
    "\n",
    "# Note: in Nt1 of Image_Modeling repo, the data was downloaded. There is \n",
    "# code for that in that nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!Check what the cell below does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the code below for this notebook\n",
    "\n",
    "# Get paths as POSIX paths\n",
    "home_path = str(pathlib.Path.home())\n",
    "data_dir = home_path + '/.keras/datasets/flower_photos' #adjust here\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# count available images\n",
    "image_count = len(list(data_dir.glob('*/*.tiff')))\n",
    "print(\"We have\", image_count, \"images.\")\n",
    "\n",
    "# Get classes\n",
    "CLASS_NAMES = np.array(\n",
    "    [item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"] # adjust here\n",
    ")\n",
    "print(\"We have the following classes in the data: \", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of images per class\n",
    "for cls in CLASS_NAMES:\n",
    "    image_count = len(list(data_dir.glob(cls+'/*.tiff')))\n",
    "    print(\"We have\", image_count, cls, \"images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all images from one label. Adjust the code below.\n",
    "# We can write a for loop to check 1 image per class label\n",
    "label1 = list(data_dir.glob('label1/*')) # replace label1\n",
    "\n",
    "# display 3 images\n",
    "for image in label1[:3]: # replace label1\n",
    "    display.display(Image.open(str(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Data Preparation Using Shell Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1- Reaching at the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Adjust the text and the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`buildings_train_generic.csv` contains the paths to the images and their respective classes. Let's look at the first five entries. First we use the [head](https://linuxhint.com/bash_head_tail_command/) command to generate the first five lines of the `buildings_train_generic.csv`. Then we redirect the output of the [head](https://linuxhint.com/bash_head_tail_command/) command to the `/tmp/input.csv` via the ['>'](https://www.cs.ait.ac.th/~on/O/oreilly/unix/upt/ch13_01.htm#UPT-ART-1023) operator. We now print the content of this file with the [cat](https://www.interserver.net/tips/kb/linux-cat-command-usage-examples/?__cf_chl_f_tk=sbsfrwcq2e.iPk93oGmvT0LSXdGVW7BuzsZsRhl85GI-1642513145-0-gaNycGzNCOU) command. We separate the cat command by using pipe operator '|'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us take a look into the training set - inspect the first 5 lines with 'head'\n",
    "!head -5 labels.csv > /tmp/input.csv | cat\n",
    "\n",
    "# This is the same thing as:\n",
    "# !head -5 labels.csv > /tmp/input.csv \n",
    "# !cat /tmp/input.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2- Correcting the name of the labels for tensor flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`If the result of the above code contains '~', continue here:`\n",
    "\n",
    "Unfortunately the Tensorflow Dataset API cannot handle '~'. So we write new files containing the user path instead of '~', named buildings_train.csv and buildings_test.csv\n",
    "\n",
    "- first we generate standard output with the content of labels_train_generic.csv with the cat command.\n",
    "- the [pipe operator](https://www.cs.ait.ac.th/~on/O/oreilly/unix/upt/ch13_01.htm#UPT-ART-1023) '|' uses the output of whats left of it as the input for whats right of it.\n",
    "- so we use the output of cat as input of the [sed](https://www.geeksforgeeks.org/sed-command-in-linux-unix-with-examples/?ref=lbp) command. Note: here the delimiter is '+'\n",
    "- the 's' in `s+~+{home_path}+g` specifies the substitution operation and 'g' stands for globally so all occurrences will be replaced.\n",
    "- finally sed `s+~+{home_path}+g` replaces all '~' with the home_path variable and the output is written to a new file via '>'\n",
    "- `home_path` is the variable we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Dataset API cannot work with the '~' character,\n",
    "# so we replace it with the specific user path using 'sed'\n",
    "# and save it in another file using '>' operator\n",
    "!cat buildings_train_generic.csv | sed 's+~+{home_path}+g' > buildings_train.csv # adjust\n",
    "!cat buildings_test_generic.csv | sed 's+~+{home_path}+g' > buildings_test.csv # adjust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first 5 elements in the train\n",
    "!head -5 buildings_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first 5 elements in the test\n",
    "!head -5 buildings_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3- Train-Validation (Holdout) Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`if the data is already split, you can skip this step`\n",
    "\n",
    "Now the paths in `buildings_train.csv` and `buildings_test.csv` are in the path format needed for Tensorflow.\n",
    "\n",
    "In order to be able to see if our model is overfitting we need to split our train set again into a train set and an evaluation set. To make results comparable we want to randomly split with a seed specified by the file random.seed. \n",
    "\n",
    "- first we use the `sort -R` command to shuffle the lines in flowers_train.csv. `--random-source=random.seed` sets the random seed.\n",
    "- then we use this output as input for the [split -l](https://www.geeksforgeeks.org/split-command-in-linux-with-examples/) command via pipe ('|').\n",
    "- `split -l` then takes the pseudo randomized data and splits it into two files after a specified number of lines. \n",
    "- the [wc -l](https://www.geeksforgeeks.org/wc-command-linux-examples/) counts the number of lines in a file.\n",
    "- So finally we get a train file with `x number` and a evaluation file with `y number` lines.\n",
    "\n",
    ">__Exercise__: use the `wc -l` command to check the length of the two files in your terminal\n",
    "\n",
    "Note that due to the `%%bash` in the beginning of the cell we can omit the usual '!' in front of the shell command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust below code (figure out what 'flowers' is for)\n",
    "\n",
    "%%bash\n",
    "# Let us also create an evaluation set from the train set.\n",
    "# We want to have a fixed seed.\n",
    "# NOTE: 'sort -R' is used to shuffle the data. If there are\n",
    "# duplicates it sorts them next to each others, which we \n",
    "# want to have, since we want to avoid evaluation leakage.\n",
    "\n",
    "echo \"files before splitting:\"\n",
    "ls flowers*  #Is flowers the name of the labels file or images file?\n",
    "sort -R buildings_train.csv --random-source=random.seed | split -l $(( $(wc -l <buildings_train.csv) - 370)) - buildings_train\n",
    "\n",
    "echo # print empty line\n",
    "echo \"files after splitting:\"\n",
    "ls flowers* #?\n",
    "# results of split are written into two files automatically: a and b refer to train and test\n",
    "mv buildings_trainaa buildings_train.csv \n",
    "mv buildings_trainab buildings_validation.csv\n",
    "echo; echo \"files after renaming:\"\n",
    "ls flowers* #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# count lines in all csv files\n",
    "wc -l *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4- Extract the Labels from Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to extract the labels from the `buildings_train.csv`. \n",
    "\n",
    "- [awk](https://www.geeksforgeeks.org/awk-command-unixlinux-examples/) lets you, amongst other things, select fields separated by white spaces in a file.\n",
    "- [uniq](https://linuxhint.com/bash_uniq_command/) removes adjacent duplicate lines from a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels from the train data \n",
    "#########################################\n",
    "# cat: read file content \n",
    "# sed: replace comma by space \n",
    "# awk: extract column 2 separated by space \n",
    "# sort: sort labels\n",
    "# uniq: extract unique labels \n",
    "# > write data to file\n",
    "!cat buildings_train.csv | sed 's/,/ /g' | awk '{print $2}' | sort | uniq > /tmp/labels.txt #adjust\n",
    "# cat: display file content \n",
    "!cat /tmp/labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5- Define Functions to Process the Data (Decoding and Loading the Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set some parameters for the model and call the register cell magic `write_and_run` again this time with the `-a` flag. This makes sure that the content of the cell is appended to `.py` and existing lines are not overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.data` builds a performance model of the input pipeline and runs an optimization algorithm to find a good allocation of its CPU budget across all parameters specified as `AUTOTUNE`. While the input pipeline is running, `tf.data` tracks the time spent in each operation, so that these times can be fed into the optimization algorithm.\n",
    "\n",
    "The [OptimizationOptions](https://www.tensorflow.org/api_docs/python/tf/data/experimental/OptimizationOptions) object gives some control over how autotune will behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a Building_Damage-Python.py\n",
    "\n",
    "# adjust the code below \n",
    "\n",
    "# We set some parameters for the model\n",
    "# image characteristics\n",
    "HEIGHT = 1024 #image height\n",
    "WIDTH = 1024 #image width\n",
    "CHANNELS = 3 #image RGB channels\n",
    "\n",
    "# label characteristics\n",
    "CLASS_NAMES = ['label1', 'label2', 'label3', 'label4', 'label5'] # put all the label names\n",
    "NCLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# algorithmic parameters\n",
    "BATCH_SIZE = 10 #adjust\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE #adjust\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # what does this code do?\n",
    "\n",
    "VALIDATION_SIZE =  # enter a number here depending on how many samples are in train set\n",
    "VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a Building_Damage-Python.py\n",
    "\n",
    "# Define the function that decodes the images--adjusted for tiff images\n",
    "def decode_image(image, reshape_dim):\n",
    "    \"\"\"decode image based on image loaded image and its size dimension\n",
    "\n",
    "    Args:\n",
    "        image (_type_): <class 'tensorflow.python.framework.ops.EagerTensor'> e.g. from tf.io.read_file(<filename>)\n",
    "        reshape_dim (_type_): list with height and width\n",
    "\n",
    "    Returns:\n",
    "        tensor representation of the image\n",
    "    \"\"\"\n",
    "     \n",
    "    # we convert tiff format to a numpy array we can compute with.\n",
    "    image = tf.image.decode_tiff(image, channels=CHANNELS)\n",
    "    # 'decode_jpeg' returns a tensor of type uint8. I replaced it with\n",
    "    # decode_tiff. We need  32bit floats for the model. Actually we want \n",
    "    # them to be in the [0,1] interval. I am not sure if we need to change\n",
    "    # them to float for tiff (?)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Now we can resize to the desired size.\n",
    "    image = tf.image.resize(image, reshape_dim)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the decoding function\n",
    "img = tf.io.read_file(home_path + '/xxx.tiff')  #adjust\n",
    "print(type(img), \"\\n\")\n",
    "\n",
    "# TODO: take the function above and decode the image\n",
    "decode_image(img,[HEIGHT, WIDTH])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function that takes a row containing paths and classes and returns the actual images and a label vector which is true at the position of the class of the image, defined by CLASS_NAMES above and false otherwise (one-hot-encoding). The decode_dataset function does this for us. It will be used later and written to the end of `image_modeling.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a Building_Damage-Python.py\n",
    "\n",
    "# check again what this cell does\n",
    "\n",
    "# The train set actually gives only the paths to the training images.\n",
    "# We want to create a dataset of training images, so we need a \n",
    "# function that can handle this for us.\n",
    "def decode_dataset(data_row):\n",
    "    # extract image path and class label for a single row from csv\n",
    "    record_defaults = ['path', 'class']\n",
    "    # read row of csv\n",
    "    filename, label_string = tf.io.decode_csv(data_row, record_defaults)\n",
    "    # read image into class 'tensorflow.python.framework.ops.EagerTensor'\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    # read label - looks like: Tensor(\"Equal:0\", shape=(5,), dtype=bool)\n",
    "    label = tf.math.equal(label_string, CLASS_NAMES)\n",
    "    return image_bytes, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell you can see how a Tensorflow data set will look like. Tensorflow data sets will be iterable objects and we can use `.decode_csv` to unpack the content into a path and a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again what this cell does\n",
    "\n",
    "# read training data for iteration and decode the csv to get filename and label\n",
    "dataset = tf.data.TextLineDataset('flowers_train.csv')\n",
    "it = iter(dataset)\n",
    "\n",
    "# unpack tensorflow object content into file path and class label string\n",
    "record_defaults = ['path', 'class'] # defines dtype\n",
    "# output dtype of decode_csv will be two strings\n",
    "# could have written ['chicken','egg'] with same outcome. But not e.g. [1,'class'].\n",
    "filename, label_string = tf.io.decode_csv(next(it), record_defaults)\n",
    "filename, label_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6- Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a Building_Damage-Python.py\n",
    "\n",
    "# Next we construct a function for pre-processing the images.\n",
    "def read_and_preprocess(image_bytes, label, augment_randomly=False):\n",
    "    \"\"\"randomly transform image, if augment_randomly == True\"\"\"\n",
    "    # transform image randomly\n",
    "    if augment_randomly:\n",
    "        # increase image size \n",
    "        image = decode_image(image_bytes, [HEIGHT + 8, WIDTH + 8])\n",
    "        # TODO: Augment the image.\n",
    "        # randomly crop image \n",
    "        image = tf.image.random_crop(image, size=[HEIGHT, WIDTH, 3])\n",
    "    # use original image \n",
    "    else:\n",
    "        image = decode_image(image_bytes, [HEIGHT, WIDTH])\n",
    "    return image, label\n",
    "\n",
    "def read_and_preprocess_with_augmentation(image_bytes, label): \n",
    "    \"\"\"read images and augment randomly\"\"\"\n",
    "    return read_and_preprocess(image_bytes, label, augment_randomly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7- Loading the Data with the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can define a function that loads and preprocesses our data by combining the functions defined above. \n",
    "- the `load_dataset` function applies (`map`) the `decode_dataset` to every element in the dataset.\n",
    "- for training:\n",
    "    - the data should use your augmentation implementation (`#TODO`).\n",
    "    - then the data will be [shuffled](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) to avoid the risk to create batches that are not representative of the overall dataset. Second answer in [this](https://datascience.stackexchange.com/questions/24511/why-should-the-data-be-shuffled-for-machine-learning-tasks) thread for more details.\n",
    "    - we can go through the dataset infinite times.\n",
    "- for evaluation:\n",
    "    - the data is neither shuffled or augmented, just read and preprocessed.\n",
    "    - we only need to go through the whole dataset once, hence `repeat(count=1)`. Will just stop after end is reached.\n",
    "- finally batches of size `batch_size` will be produced with each iteration step.\n",
    "- with `prefetch(buffer_size=AUTOTUNE)` an optimized number batches are prepared while prior ones are trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a Building_Damage-Python.py\n",
    "\n",
    "# Now we can create the dataset.\n",
    "def load_dataset(file_of_filenames, batch_size, training=True):\n",
    "    # We create a TensorFlow Dataset from the list of files.\n",
    "    # This dataset does not load the data into memory, but instead\n",
    "    # pulls batches one after another.\n",
    "    dataset = tf.data.TextLineDataset(filenames=file_of_filenames).\\\n",
    "        map(decode_dataset)\n",
    "    \n",
    "    # important: augmentation only used during training!\n",
    "    if training:\n",
    "        # TODO: Use augmentation here.\n",
    "        dataset = dataset.map(read_and_preprocess_with_augmentation).\\\n",
    "            shuffle(SHUFFLE_BUFFER).\\\n",
    "            repeat(count=None) # Infinite iterations\n",
    "\n",
    "        # # previous function that got replaced by another with augmentation\n",
    "        # dataset = dataset.map(read_and_preprocess).\\\n",
    "        #     shuffle(SHUFFLE_BUFFER).\\\n",
    "        #     repeat(count=None) # Infinite iterations\n",
    "    \n",
    "    else: \n",
    "        # Evaluation or testing\n",
    "        dataset = dataset.map(read_and_preprocess).\\\n",
    "            repeat(count=1) # One iteration\n",
    "            \n",
    "    # The dataset will produce batches of BATCH_SIZE and will automatically\n",
    "    # prepare an optimized number of batches while the prior one is trained on.\n",
    "    return dataset.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use load_dataset function \n",
    "\n",
    "# check if data loading works as intended.\n",
    "train_path = 'flowers_train.csv'\n",
    "train_data = load_dataset(train_path, 1)\n",
    "# Create an iterator that runs over the training dataset.\n",
    "it = iter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and see the pictures and labels\n",
    "# use 'next' to go to next image (as 'it' is an iterator that runs over the training dataset)\n",
    "img_batch, labels = next(it)\n",
    "# show random image\n",
    "image = img_batch[0]\n",
    "plt.imshow(image)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show another image\n",
    "img_batch, labels = next(it) \n",
    "image = img_batch[0]\n",
    "plt.imshow(image)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Check Parameters from Python File before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "# import tensorflow as tf --> already imported in part2\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "\n",
    "# import image_modeling.py file created with NB1\n",
    "import Building_Damage-Python\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in case you need to clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import variables from Building_Damage-Python.py file\n",
    "HEIGHT = image_modeling.HEIGHT\n",
    "WIDTH = image_modeling.WIDTH\n",
    "NCLASSES = image_modeling.NCLASSES\n",
    "CLASS_NAMES = image_modeling.CLASS_NAMES\n",
    "BATCH_SIZE = image_modeling.BATCH_SIZE\n",
    "TRAINING_SIZE = !wc -l < buildings_train.csv\n",
    "TRAINING_STEPS = int(TRAINING_SIZE[0]) // BATCH_SIZE\n",
    "\n",
    "# set paths to data sets\n",
    "TRAIN_PATH = 'buildings_train.csv'\n",
    "EVAL_PATH = 'buildings_validation.csv'\n",
    "TEST_PATH = 'buildings_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check if the variables now contain the correct values.\n",
    "print(HEIGHT)\n",
    "print(CLASS_NAMES)\n",
    "print(NCLASSES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Load Pretrained Models (Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## refer to Nt2 of Image_Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Train the Model/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Metrics for Model Performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
