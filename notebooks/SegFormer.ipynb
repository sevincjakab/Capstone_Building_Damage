{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infos - Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube video explaining how to convert images and masks to tensor flow:\n",
    "\n",
    "https://www.youtube.com/watch?v=C5CbsTDwQM0\n",
    "\n",
    "Github link of the video: https://github.com/nikhilroxtomar/tf.data-TensorFlow-Input-Data-Pipeline-for-Semantic-Segmentation\n",
    "\n",
    "\n",
    "\n",
    "### Links for notebooks and blogs used to prepare this notebook:\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/segformer#\n",
    "\n",
    "https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb\n",
    "\n",
    "https://huggingface.co/blog/fine-tune-segformer (I am not 100% sure if this blog is using tensor flow)\n",
    "\n",
    "https://github.com/deep-diver/segformer-tf-transformers/blob/main/notebooks/TFSegFormer_Finetune.ipynb\n",
    "\n",
    "I didn't use this one yet: https://github.com/deep-diver/segformer-tf-transformers/blob/main/notebooks/TFSegFormer_ONNX.ipynb\n",
    "\n",
    "https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb#scrollTo=Mp9xJcHP2TTP\n",
    "\n",
    "Setting up a model from scratch on tensor flow: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#scrollTo=-47O6_GLdRuT\n",
    "\n",
    "\n",
    "\n",
    "### Additional Info:\n",
    "https://medium.com/geekculture/semantic-segmentation-with-segformer-2501543d2be4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transformers from HuggingFace to load the model. Later in the\n",
    "## notebook, the model was downloaded via tenser flow. I am not sure \n",
    "### if we still need this cell. \n",
    "\n",
    "# Comment it out after you run it\n",
    "#%pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have access to a GPU. Later for the cloud\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages. This will be moved to the requirements.txt later\n",
    "# !pip install datasets==2.3.2\n",
    "# !pip install numpy==1.23.0\n",
    "# !pip install pillow==9.1.1\n",
    "# !pip install matplotlib==3.5.2\n",
    "#!pip install tensorflow==2.9.0 # inside requirement_dev we installed 2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cel was from a different notebook. \n",
    "## I need to check if we still need to install this. \n",
    "\n",
    "# comment out after running\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we do not need those because we have our own data\n",
    "#from datasets import load_dataset, load_metric\n",
    "#from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from transformers import (\n",
    "    DefaultDataCollator,\n",
    "    SegformerFeatureExtractor,\n",
    "    TFSegformerForSemanticSegmentation,\n",
    "    create_optimizer,\n",
    ")\n",
    "from transformers.keras_callbacks import KerasMetricCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For the purpose of this example, we will keep the runtime short\n",
    "(2 epochs only). But we will provide a link to a model checkpoint\n",
    "that was trained for 50 epochs with the exact same code.\n",
    "'''\n",
    "epochs = 2\n",
    "lr = 0.00006\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell for now\n",
    "\n",
    "\n",
    "# comment out after running\n",
    "#!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing images for Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Imges: Option1\n",
    "\n",
    "You can run 'python data_copy.py' on Terminal or do as in the next 2 cells and run the script on notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this cell for now \n",
    "\n",
    "# change the path to your 'data_copy.py'\n",
    "# script_path = '/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/python_files/data_copy.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 12 - Masks: 12\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/mexico-earthquake_00000005_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/mexico-earthquake_00000005_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/santa-rosa-wildfire_00000028_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/santa-rosa-wildfire_00000028_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/mexico-earthquake_00000022_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/mexico-earthquake_00000022_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/mexico-earthquake_00000010_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/mexico-earthquake_00000010_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/mexico-earthquake_00000006_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/mexico-earthquake_00000006_pre_disaster.png\n",
      "tf.Tensor(\n",
      "[[[0.36078432 0.43529412 0.5882353 ]\n",
      "  [0.39607844 0.4509804  0.5529412 ]\n",
      "  [0.4627451  0.50980395 0.58431375]\n",
      "  ...\n",
      "  [0.34509805 0.42352942 0.49019608]\n",
      "  [0.45490196 0.5372549  0.6156863 ]\n",
      "  [0.44705883 0.5294118  0.57254905]]\n",
      "\n",
      " [[0.4117647  0.46666667 0.5882353 ]\n",
      "  [0.45882353 0.5176471  0.5882353 ]\n",
      "  [0.47843137 0.5372549  0.5882353 ]\n",
      "  ...\n",
      "  [0.34117648 0.41568628 0.4509804 ]\n",
      "  [0.36078432 0.43137255 0.4627451 ]\n",
      "  [0.36862746 0.44313726 0.47058824]]\n",
      "\n",
      " [[0.4509804  0.52156866 0.62352943]\n",
      "  [0.39215687 0.47058824 0.5411765 ]\n",
      "  [0.3372549  0.41960785 0.48235294]\n",
      "  ...\n",
      "  [0.3372549  0.42352942 0.4392157 ]\n",
      "  [0.34509805 0.42745098 0.44313726]\n",
      "  [0.34509805 0.41960785 0.44313726]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.22352941 0.29411766 0.28235295]\n",
      "  [0.20392157 0.2784314  0.2627451 ]\n",
      "  [0.22745098 0.3019608  0.2784314 ]\n",
      "  ...\n",
      "  [0.3372549  0.39607844 0.35686275]\n",
      "  [0.2784314  0.33333334 0.29803923]\n",
      "  [0.28235295 0.35686275 0.31764707]]\n",
      "\n",
      " [[0.21568628 0.29803923 0.28627452]\n",
      "  [0.20392157 0.28235295 0.2627451 ]\n",
      "  [0.1764706  0.24313726 0.22745098]\n",
      "  ...\n",
      "  [0.23529412 0.28627452 0.3137255 ]\n",
      "  [0.22745098 0.30588236 0.29411766]\n",
      "  [0.30588236 0.41960785 0.35686275]]\n",
      "\n",
      " [[0.22745098 0.31764707 0.3019608 ]\n",
      "  [0.20392157 0.28235295 0.27058825]\n",
      "  [0.21960784 0.2901961  0.29803923]\n",
      "  ...\n",
      "  [0.3372549  0.38431373 0.39607844]\n",
      "  [0.24705882 0.30980393 0.30980393]\n",
      "  [0.21176471 0.3019608  0.27450982]]], shape=(256, 256, 3), dtype=float32) tf.Tensor(\n",
      "[[[0.2509804 0.2509804 0.2509804]\n",
      "  [0.5019608 0.5019608 0.5019608]\n",
      "  [0.5019608 0.5019608 0.5019608]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.5019608 0.5019608 0.5019608]\n",
      "  [1.        1.        1.       ]\n",
      "  [1.        1.        1.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.5019608 0.5019608 0.5019608]\n",
      "  [1.        1.        1.       ]\n",
      "  [1.        1.        1.       ]\n",
      "  ...\n",
      "  [0.2509804 0.2509804 0.2509804]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.5019608 0.5019608 0.5019608]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]], shape=(256, 256, 3), dtype=float32)\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/mexico-earthquake_00000012_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/mexico-earthquake_00000012_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/santa-rosa-wildfire_00000021_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/santa-rosa-wildfire_00000021_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/santa-rosa-wildfire_00000043_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/santa-rosa-wildfire_00000043_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/santa-rosa-wildfire_00000038_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/santa-rosa-wildfire_00000038_pre_disaster.png\n",
      "tf.Tensor(\n",
      "[[[0.36078432 0.4117647  0.4627451 ]\n",
      "  [0.45882353 0.5137255  0.6       ]\n",
      "  [0.32941177 0.38431373 0.41568628]\n",
      "  ...\n",
      "  [0.2784314  0.33333334 0.3372549 ]\n",
      "  [0.27450982 0.3372549  0.3372549 ]\n",
      "  [0.24705882 0.3254902  0.31764707]]\n",
      "\n",
      " [[0.38039216 0.43529412 0.43137255]\n",
      "  [0.3137255  0.35686275 0.36862746]\n",
      "  [0.33333334 0.38431373 0.3882353 ]\n",
      "  ...\n",
      "  [0.29411766 0.35686275 0.3647059 ]\n",
      "  [0.2901961  0.3647059  0.37254903]\n",
      "  [0.27450982 0.34901962 0.3529412 ]]\n",
      "\n",
      " [[0.33333334 0.39215687 0.3647059 ]\n",
      "  [0.3019608  0.3529412  0.3254902 ]\n",
      "  [0.30980393 0.3647059  0.3372549 ]\n",
      "  ...\n",
      "  [0.29411766 0.35686275 0.3647059 ]\n",
      "  [0.28235295 0.34901962 0.36078432]\n",
      "  [0.2627451  0.33333334 0.34117648]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.29411766 0.36862746 0.37254903]\n",
      "  [0.33333334 0.4117647  0.43529412]\n",
      "  [0.3647059  0.4392157  0.47058824]\n",
      "  ...\n",
      "  [0.19215687 0.2784314  0.22745098]\n",
      "  [0.19607843 0.29411766 0.24313726]\n",
      "  [0.19215687 0.30980393 0.25490198]]\n",
      "\n",
      " [[0.28627452 0.3529412  0.34901962]\n",
      "  [0.32941177 0.39215687 0.40392157]\n",
      "  [0.34509805 0.39215687 0.40784314]\n",
      "  ...\n",
      "  [0.19607843 0.28627452 0.23921569]\n",
      "  [0.2        0.2901961  0.24705882]\n",
      "  [0.19215687 0.29803923 0.25882354]]\n",
      "\n",
      " [[0.36862746 0.44313726 0.4392157 ]\n",
      "  [0.49803922 0.5568628  0.56078434]\n",
      "  [0.49411765 0.5411765  0.54509807]\n",
      "  ...\n",
      "  [0.19215687 0.27450982 0.24313726]\n",
      "  [0.19607843 0.2901961  0.25490198]\n",
      "  [0.21176471 0.3254902  0.2784314 ]]], shape=(256, 256, 3), dtype=float32) tf.Tensor(\n",
      "[[[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [1.        1.        1.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]\n",
      "\n",
      " [[0.5019608 0.5019608 0.5019608]\n",
      "  [1.        1.        1.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]\n",
      "  [0.        0.        0.       ]]], shape=(256, 256, 3), dtype=float32)\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/santa-rosa-wildfire_00000045_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/santa-rosa-wildfire_00000045_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/santa-rosa-wildfire_00000019_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/santa-rosa-wildfire_00000019_pre_disaster.png\n",
      "/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/images/mexico-earthquake_00000025_post_disaster.png /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized/masks/mexico-earthquake_00000025_pre_disaster.png\n",
      "tf.Tensor(\n",
      "[[[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.29411766 0.3882353  0.2784314 ]\n",
      "  [0.32156864 0.3647059  0.2784314 ]\n",
      "  [0.21176471 0.23529412 0.1882353 ]]\n",
      "\n",
      " [[0.38039216 0.4627451  0.45882353]\n",
      "  [0.44705883 0.52156866 0.52156866]\n",
      "  [0.54509807 0.6313726  0.6509804 ]\n",
      "  ...\n",
      "  [0.23529412 0.35686275 0.24313726]\n",
      "  [0.2784314  0.36078432 0.2627451 ]\n",
      "  [0.29803923 0.31764707 0.24705882]]\n",
      "\n",
      " [[0.4392157  0.5137255  0.5176471 ]\n",
      "  [0.4862745  0.54901963 0.56078434]\n",
      "  [0.5019608  0.58431375 0.6039216 ]\n",
      "  ...\n",
      "  [0.27058825 0.38431373 0.26666668]\n",
      "  [0.25882354 0.36078432 0.25490198]\n",
      "  [0.21960784 0.2784314  0.20784314]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.4862745  0.5686275  0.54509807]\n",
      "  [0.42745098 0.5372549  0.49803922]\n",
      "  [0.46666667 0.5803922  0.5372549 ]\n",
      "  ...\n",
      "  [0.21176471 0.29411766 0.23137255]\n",
      "  [0.3137255  0.39607844 0.3137255 ]\n",
      "  [0.2784314  0.32941177 0.2784314 ]]\n",
      "\n",
      " [[0.47058824 0.5647059  0.53333336]\n",
      "  [0.32156864 0.42745098 0.39215687]\n",
      "  [0.65882355 0.7294118  0.6901961 ]\n",
      "  ...\n",
      "  [0.3019608  0.39215687 0.31764707]\n",
      "  [0.3137255  0.3764706  0.30980393]\n",
      "  [0.2627451  0.30588236 0.25882354]]\n",
      "\n",
      " [[0.4862745  0.6        0.56078434]\n",
      "  [0.48235294 0.5921569  0.5568628 ]\n",
      "  [0.47843137 0.5568628  0.52156866]\n",
      "  ...\n",
      "  [0.27058825 0.34901962 0.29803923]\n",
      "  [0.27450982 0.31764707 0.27450982]\n",
      "  [0.23921569 0.2901961  0.23921569]]], shape=(256, 256, 3), dtype=float32) tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# I used Option 2\n",
    "# change the path to your 'data_copy.py'\n",
    "\n",
    "# !python /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/python_files/data_copy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Images: Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this step if you did option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 12 - Masks: 12\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing with TensorFlow\n",
    "\n",
    "#This notebook demonstrates how to load and preprocess image and mask data using TensorFlow's tf.data API.\n",
    "\n",
    "## Step 1: Load the Dataset - Image and Mask Paths\n",
    "\n",
    "#Let's start by loading the dataset, which contains images and\n",
    "# their corresponding masks. The paths to the images and masks will be stored in separate lists.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "# before running this cell, you need to reorganize your data folder.\n",
    "## One folder should have 'images' and the other 'masks with labels'. \n",
    "### You can mix all the disasters. \n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    images = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"masks/*\")))\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "# Define the path to the dataset directory\n",
    "path = \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/data/xBD_test_subset_reorganized\"\n",
    "images, masks = load_data(path)\n",
    "\n",
    "print(f\"Images: {len(images)} - Masks: {len(masks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to process data\n",
    "\n",
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (256, 256))\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (256, 256))\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def preprocess(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
    "    images.set_shape([256, 256, 3])\n",
    "    masks.set_shape([256, 256, 3])\n",
    "\n",
    "    return images, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256, 256, 3) (4, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "def tf_dataset(x, y, batch=4):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(2)\n",
    "    return dataset\n",
    "\n",
    "# Create the TensorFlow dataset\n",
    "dataset= tf_dataset(images, masks, batch=4)\n",
    "ds=dataset\n",
    "# Let's print the dimensions of the first batch of preprocessed images and masks\n",
    "for x, y in ds:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.42352942 0.5411765  0.57254905]\n",
      "  [0.4745098  0.5882353  0.6156863 ]\n",
      "  [0.4392157  0.54509807 0.5764706 ]\n",
      "  ...\n",
      "  [0.27058825 0.32941177 0.28627452]\n",
      "  [0.38431373 0.4627451  0.42352942]\n",
      "  [0.21568628 0.28235295 0.2509804 ]]\n",
      "\n",
      " [[0.3372549  0.4392157  0.45882353]\n",
      "  [0.43529412 0.54509807 0.57254905]\n",
      "  [0.46666667 0.57254905 0.60784316]\n",
      "  ...\n",
      "  [0.25882354 0.29803923 0.2627451 ]\n",
      "  [0.18039216 0.23921569 0.21176471]\n",
      "  [0.1882353  0.24313726 0.21960784]]\n",
      "\n",
      " [[0.39607844 0.5019608  0.53333336]\n",
      "  [0.38039216 0.49411765 0.52156866]\n",
      "  [0.41960785 0.5372549  0.5686275 ]\n",
      "  ...\n",
      "  [0.18431373 0.24705882 0.2       ]\n",
      "  [0.27058825 0.33333334 0.2784314 ]\n",
      "  [0.21568628 0.27450982 0.24313726]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.25882354 0.30588236 0.2627451 ]\n",
      "  [0.34117648 0.41568628 0.39215687]\n",
      "  [0.33333334 0.40392157 0.40392157]\n",
      "  ...\n",
      "  [0.43137255 0.4862745  0.43529412]\n",
      "  [0.44313726 0.4862745  0.44313726]\n",
      "  [0.42352942 0.4745098  0.43137255]]\n",
      "\n",
      " [[0.30980393 0.36862746 0.3647059 ]\n",
      "  [0.28627452 0.36078432 0.36078432]\n",
      "  [0.3882353  0.47058824 0.47843137]\n",
      "  ...\n",
      "  [0.43137255 0.4862745  0.44313726]\n",
      "  [0.43529412 0.4862745  0.44705883]\n",
      "  [0.42745098 0.4862745  0.44313726]]\n",
      "\n",
      " [[0.36078432 0.43529412 0.44705883]\n",
      "  [0.4509804  0.5372549  0.56078434]\n",
      "  [0.4627451  0.5529412  0.5803922 ]\n",
      "  ...\n",
      "  [0.43137255 0.47843137 0.43529412]\n",
      "  [0.44313726 0.4862745  0.44313726]\n",
      "  [0.41960785 0.4745098  0.43529412]]], shape=(256, 256, 3), dtype=float32) tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# check values inside the tensors\n",
    "x = x[0] # images\n",
    "y = y[0] # masks with labels\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR BIG DATASET\n",
    "# ds = dataset.shuffle(seed=1, buffer_size=1000)\n",
    "\n",
    "# # Calculate the number of samples for validation set\n",
    "# val_size = int(len(images) * 0.5)  # 20% of the data for validation\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# train_ds = ds.take(len(images) - val_size)\n",
    "# val_ds = ds.skip(len(images) - val_size)\n",
    "\n",
    "# # Optionally, you can further batch the validation dataset\n",
    "# val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "# # Check the number of samples in each dataset\n",
    "# print(\"Train samples:\", len(list(train_ds)))\n",
    "# print(\"Validation samples:\", len(list(val_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2\n",
      "Validation samples: 1\n"
     ]
    }
   ],
   "source": [
    "# FOR SMALL DATASET\n",
    "# Previously defined code for creating the dataset\n",
    "\n",
    "ds = dataset.shuffle(seed=1, buffer_size=1000)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_ds = ds.take(2)\n",
    "val_ds = ds.skip(2)\n",
    "\n",
    "# Optionally, you can further batch the validation dataset\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "# Check the number of samples in each dataset\n",
    "print(\"Train samples:\", len(list(train_ds)))\n",
    "print(\"Validation samples:\", len(list(val_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[[0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    ...\n",
      "    [0.29411766 0.3882353  0.2784314 ]\n",
      "    [0.32156864 0.3647059  0.2784314 ]\n",
      "    [0.21176471 0.23529412 0.1882353 ]]\n",
      "\n",
      "   [[0.38039216 0.4627451  0.45882353]\n",
      "    [0.44705883 0.52156866 0.52156866]\n",
      "    [0.54509807 0.6313726  0.6509804 ]\n",
      "    ...\n",
      "    [0.23529412 0.35686275 0.24313726]\n",
      "    [0.2784314  0.36078432 0.2627451 ]\n",
      "    [0.29803923 0.31764707 0.24705882]]\n",
      "\n",
      "   [[0.4392157  0.5137255  0.5176471 ]\n",
      "    [0.4862745  0.54901963 0.56078434]\n",
      "    [0.5019608  0.58431375 0.6039216 ]\n",
      "    ...\n",
      "    [0.27058825 0.38431373 0.26666668]\n",
      "    [0.25882354 0.36078432 0.25490198]\n",
      "    [0.21960784 0.2784314  0.20784314]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.4862745  0.5686275  0.54509807]\n",
      "    [0.42745098 0.5372549  0.49803922]\n",
      "    [0.46666667 0.5803922  0.5372549 ]\n",
      "    ...\n",
      "    [0.21176471 0.29411766 0.23137255]\n",
      "    [0.3137255  0.39607844 0.3137255 ]\n",
      "    [0.2784314  0.32941177 0.2784314 ]]\n",
      "\n",
      "   [[0.47058824 0.5647059  0.53333336]\n",
      "    [0.32156864 0.42745098 0.39215687]\n",
      "    [0.65882355 0.7294118  0.6901961 ]\n",
      "    ...\n",
      "    [0.3019608  0.39215687 0.31764707]\n",
      "    [0.3137255  0.3764706  0.30980393]\n",
      "    [0.2627451  0.30588236 0.25882354]]\n",
      "\n",
      "   [[0.4862745  0.6        0.56078434]\n",
      "    [0.48235294 0.5921569  0.5568628 ]\n",
      "    [0.47843137 0.5568628  0.52156866]\n",
      "    ...\n",
      "    [0.27058825 0.34901962 0.29803923]\n",
      "    [0.27450982 0.31764707 0.27450982]\n",
      "    [0.23921569 0.2901961  0.23921569]]]\n",
      "\n",
      "\n",
      "  [[[0.36078432 0.4117647  0.4627451 ]\n",
      "    [0.45882353 0.5137255  0.6       ]\n",
      "    [0.32941177 0.38431373 0.41568628]\n",
      "    ...\n",
      "    [0.2784314  0.33333334 0.3372549 ]\n",
      "    [0.27450982 0.3372549  0.3372549 ]\n",
      "    [0.24705882 0.3254902  0.31764707]]\n",
      "\n",
      "   [[0.38039216 0.43529412 0.43137255]\n",
      "    [0.3137255  0.35686275 0.36862746]\n",
      "    [0.33333334 0.38431373 0.3882353 ]\n",
      "    ...\n",
      "    [0.29411766 0.35686275 0.3647059 ]\n",
      "    [0.2901961  0.3647059  0.37254903]\n",
      "    [0.27450982 0.34901962 0.3529412 ]]\n",
      "\n",
      "   [[0.33333334 0.39215687 0.3647059 ]\n",
      "    [0.3019608  0.3529412  0.3254902 ]\n",
      "    [0.30980393 0.3647059  0.3372549 ]\n",
      "    ...\n",
      "    [0.29411766 0.35686275 0.3647059 ]\n",
      "    [0.28235295 0.34901962 0.36078432]\n",
      "    [0.2627451  0.33333334 0.34117648]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.29411766 0.36862746 0.37254903]\n",
      "    [0.33333334 0.4117647  0.43529412]\n",
      "    [0.3647059  0.4392157  0.47058824]\n",
      "    ...\n",
      "    [0.19215687 0.2784314  0.22745098]\n",
      "    [0.19607843 0.29411766 0.24313726]\n",
      "    [0.19215687 0.30980393 0.25490198]]\n",
      "\n",
      "   [[0.28627452 0.3529412  0.34901962]\n",
      "    [0.32941177 0.39215687 0.40392157]\n",
      "    [0.34509805 0.39215687 0.40784314]\n",
      "    ...\n",
      "    [0.19607843 0.28627452 0.23921569]\n",
      "    [0.2        0.2901961  0.24705882]\n",
      "    [0.19215687 0.29803923 0.25882354]]\n",
      "\n",
      "   [[0.36862746 0.44313726 0.4392157 ]\n",
      "    [0.49803922 0.5568628  0.56078434]\n",
      "    [0.49411765 0.5411765  0.54509807]\n",
      "    ...\n",
      "    [0.19215687 0.27450982 0.24313726]\n",
      "    [0.19607843 0.2901961  0.25490198]\n",
      "    [0.21176471 0.3254902  0.2784314 ]]]\n",
      "\n",
      "\n",
      "  [[[0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    ...\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]]\n",
      "\n",
      "   [[0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    ...\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]]\n",
      "\n",
      "   [[0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    ...\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]\n",
      "    [0.         0.         0.        ]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.23921569 0.3254902  0.41960785]\n",
      "    [0.18431373 0.2627451  0.29411766]\n",
      "    [0.1882353  0.26666668 0.23921569]\n",
      "    ...\n",
      "    [0.27058825 0.3254902  0.35686275]\n",
      "    [0.30980393 0.38039216 0.3882353 ]\n",
      "    [0.34117648 0.41960785 0.4117647 ]]\n",
      "\n",
      "   [[0.31764707 0.4117647  0.5176471 ]\n",
      "    [0.21568628 0.3254902  0.3764706 ]\n",
      "    [0.1764706  0.29411766 0.27450982]\n",
      "    ...\n",
      "    [0.34117648 0.3882353  0.40392157]\n",
      "    [0.32156864 0.38431373 0.39215687]\n",
      "    [0.3137255  0.38039216 0.37254903]]\n",
      "\n",
      "   [[0.31764707 0.4117647  0.5176471 ]\n",
      "    [0.2901961  0.40784314 0.4745098 ]\n",
      "    [0.25490198 0.37254903 0.38039216]\n",
      "    ...\n",
      "    [0.54509807 0.5921569  0.5921569 ]\n",
      "    [0.34509805 0.39215687 0.40392157]\n",
      "    [0.3372549  0.39215687 0.39607844]]]\n",
      "\n",
      "\n",
      "  [[[0.38039216 0.43137255 0.43529412]\n",
      "    [0.3882353  0.4392157  0.44313726]\n",
      "    [0.36862746 0.41960785 0.42352942]\n",
      "    ...\n",
      "    [0.29411766 0.4117647  0.34117648]\n",
      "    [0.32941177 0.43137255 0.39215687]\n",
      "    [0.29411766 0.3764706  0.35686275]]\n",
      "\n",
      "   [[0.4117647  0.44705883 0.45490196]\n",
      "    [0.39215687 0.41568628 0.40784314]\n",
      "    [0.40784314 0.44313726 0.42745098]\n",
      "    ...\n",
      "    [0.30980393 0.42352942 0.3529412 ]\n",
      "    [0.30980393 0.42352942 0.39215687]\n",
      "    [0.27058825 0.3647059  0.34509805]]\n",
      "\n",
      "   [[0.34901962 0.4392157  0.42352942]\n",
      "    [0.36862746 0.42745098 0.40784314]\n",
      "    [0.42745098 0.47843137 0.45882353]\n",
      "    ...\n",
      "    [0.30980393 0.4117647  0.34901962]\n",
      "    [0.31764707 0.43137255 0.38431373]\n",
      "    [0.29411766 0.40392157 0.35686275]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.36862746 0.4509804  0.4627451 ]\n",
      "    [0.34117648 0.41568628 0.42745098]\n",
      "    [0.39607844 0.48235294 0.49411765]\n",
      "    ...\n",
      "    [0.3137255  0.35686275 0.3372549 ]\n",
      "    [0.32156864 0.38039216 0.3647059 ]\n",
      "    [0.27058825 0.34901962 0.3372549 ]]\n",
      "\n",
      "   [[0.3647059  0.43137255 0.4509804 ]\n",
      "    [0.37254903 0.4509804  0.46666667]\n",
      "    [0.36862746 0.45490196 0.45882353]\n",
      "    ...\n",
      "    [0.29803923 0.36078432 0.34117648]\n",
      "    [0.28627452 0.3254902  0.3019608 ]\n",
      "    [0.3019608  0.36078432 0.34509805]]\n",
      "\n",
      "   [[0.3647059  0.42745098 0.4392157 ]\n",
      "    [0.36078432 0.43529412 0.4392157 ]\n",
      "    [0.36078432 0.44313726 0.44705883]\n",
      "    ...\n",
      "    [0.29411766 0.3882353  0.34901962]\n",
      "    [0.28235295 0.3529412  0.3137255 ]\n",
      "    [0.29803923 0.35686275 0.32941177]]]]], shape=(1, 4, 256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch from the validation dataset\n",
    "val_batch = next(iter(val_ds))\n",
    "\n",
    "# Access the pixel_values from the validation batch\n",
    "pixel_values = val_batch[0]\n",
    "print(pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define labels\n",
    "\n",
    "id2label = {\n",
    "\"no-damage\": 0,\n",
    "\"minor-damage\": 1,\n",
    "\"major-damage\": 2,\n",
    "\"destroyed\": 3\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "\"0\": \"no-damage\",\n",
    "\"1\": \"minor-damage\",\n",
    "\"2\": \"major-damage\",\n",
    "\"3\": \"destroyed\"\n",
    "}\n",
    "\n",
    "num_labels = len(id2label)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (1.25.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'datasets.utils.version.Version'> for field version is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# install libraries for the next cell\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install datasets\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_metric\n",
      "File \u001b[0;32m~/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/datasets/__init__.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39marrow_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, concatenate_datasets\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39marrow_reader\u001b[39;00m \u001b[39mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbuilder\u001b[39;00m \u001b[39mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcombine\u001b[39;00m \u001b[39mimport\u001b[39;00m interleave_datasets\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdataset_dict\u001b[39;00m \u001b[39mimport\u001b[39;00m DatasetDict, IterableDatasetDict\n",
      "File \u001b[0;32m~/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/datasets/builder.py:84\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mManualDownloadError\u001b[39;00m(DatasetBuildError):\n\u001b[1;32m     81\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[39m@dataclass\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mBuilderConfig\u001b[39;49;00m:\n\u001b[1;32m     86\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m\"\"\"Base class for :class:`DatasetBuilder` data configuration.\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[39m    DatasetBuilder subclasses with data configuration options should subclass\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m        description (:obj:`str`, optional):\u001b[39;49;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m     99\u001b[0m     name: \u001b[39mstr\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m\"\u001b[39;49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/dataclasses.py:1223\u001b[0m, in \u001b[0;36mdataclass\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[39mreturn\u001b[39;00m wrap\n\u001b[1;32m   1222\u001b[0m \u001b[39m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(\u001b[39mcls\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/dataclasses.py:1213\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mreturn\u001b[39;00m _process_class(\u001b[39mcls\u001b[39;49m, init, \u001b[39mrepr\u001b[39;49m, eq, order, unsafe_hash,\n\u001b[1;32m   1214\u001b[0m                           frozen, match_args, kw_only, slots,\n\u001b[1;32m   1215\u001b[0m                           weakref_slot)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/dataclasses.py:958\u001b[0m, in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m    955\u001b[0m         kw_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m         \u001b[39m# Otherwise it's a field of some type.\u001b[39;00m\n\u001b[0;32m--> 958\u001b[0m         cls_fields\u001b[39m.\u001b[39mappend(_get_field(\u001b[39mcls\u001b[39;49m, name, \u001b[39mtype\u001b[39;49m, kw_only))\n\u001b[1;32m    960\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m cls_fields:\n\u001b[1;32m    961\u001b[0m     fields[f\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m f\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/dataclasses.py:815\u001b[0m, in \u001b[0;36m_get_field\u001b[0;34m(cls, a_name, a_type, default_kw_only)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# For real fields, disallow mutable defaults.  Use unhashable as a proxy\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# indicator for mutability.  Read the __hash__ attribute from the class,\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m# not the instance.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39m_field_type \u001b[39mis\u001b[39;00m _FIELD \u001b[39mand\u001b[39;00m f\u001b[39m.\u001b[39mdefault\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__hash__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmutable default \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f\u001b[39m.\u001b[39mdefault)\u001b[39m}\u001b[39;00m\u001b[39m for field \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    816\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m is not allowed: use default_factory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[0;31mValueError\u001b[0m: mutable default <class 'datasets.utils.version.Version'> for field version is not allowed: use default_factory"
     ]
    }
   ],
   "source": [
    "# install libraries to be able to install the evaluation metrics in the next cell\n",
    "## Error!\n",
    "!pip install datasets\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m metric \u001b[39m=\u001b[39m load_metric(\u001b[39m\"\u001b[39m\u001b[39mmean_iou\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_metrics\u001b[39m(eval_pred):\n",
      "\u001b[1;32m      5\u001b[0m     logits, labels \u001b[39m=\u001b[39m eval_pred\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_metric' is not defined"
     ]
    }
   ],
   "source": [
    "# Error!\n",
    "\n",
    "'''\n",
    "Once the metric is loaded, you can use it to evaluate the performance \n",
    "of your model on a specific task, such as semantic segmentation, \n",
    "where the \"mean_iou\" (mean Intersection over Union) is a common evaluation metric.\n",
    "'''\n",
    "\n",
    "metric = load_metric(\"mean_iou\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # logits are of shape (batch_size, num_labels, height, width), so\n",
    "    # we first transpose them to (batch_size, height, width, num_labels)\n",
    "    logits = tf.transpose(logits, perm=[0, 2, 3, 1])\n",
    "    # scale the logits to the size of the label\n",
    "    logits_resized = tf.image.resize(\n",
    "        logits,\n",
    "        size=tf.shape(labels)[1:],\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "    # compute the prediction labels and compute the metric\n",
    "    pred_labels = tf.argmax(logits_resized, axis=-1)\n",
    "    metrics = metric.compute(\n",
    "        predictions=pred_labels,\n",
    "        references=labels,\n",
    "        num_labels=num_labels,\n",
    "        ignore_index=-1,\n",
    "        reduce_labels=feature_extractor.reduce_labels,\n",
    "    )\n",
    "    return {\"val_\" + k: v for k, v in metrics.items()}\n",
    "\n",
    "\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=compute_metrics,\n",
    "    eval_dataset=val_set,\n",
    "    batch_size=batch_size,\n",
    "    label_cols=[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323e70ea289b465d9fd9ad462f4b9520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()lve/main/config.json:   0%|          | 0.00/70.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e8a83beed84076a7e10c119a00db67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 01:14:03.910591: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x147361b00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-01 01:14:03.910718: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-08-01 01:14:04.038005: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x1471adee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x1471afc40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at nvidia/mit-b0 were not used when initializing TFSegformerForSemanticSegmentation: ['classifier']\n",
      "- This IS expected if you are initializing TFSegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFSegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFSegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "model_checkpoint = \"nvidia/mit-b0\"\n",
    "model = TFSegformerForSemanticSegmentation.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,  # Will ensure the segmentation specific components are reinitialized.\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "model.compile(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_segformer_for_semantic_segmentation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " segformer (TFSegformerMain  multiple                  3319392   \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " decode_head (TFSegformerDe  multiple                  396292    \n",
      " codeHead)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3715684 (14.17 MB)\n",
      "Trainable params: 3715172 (14.17 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1642, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filekaed2bas.py\", line 41, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).segformer, (ag__.ld(pixel_values),), dict(output_attentions=ag__.ld(output_attentions), output_hidden_states=True, return_dict=ag__.ld(return_dict)), fscope)\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filek7eal_6g.py\", line 15, in tf__call\n        encoder_outputs = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(pixel_values),), dict(output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 103, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.converted_call(ag__.ld(zip), (ag__.ld(self).embeddings, ag__.ld(self).block, ag__.ld(self).layer_norms), None, fscope),), None, fscope), None, loop_body_1, get_state_4, set_state_4, ('all_hidden_states', 'all_self_attentions', 'hidden_states'), {'iterate_names': '(idx, x)'})\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 27, in loop_body_1\n        hidden_states, height, width = ag__.converted_call(ag__.ld(embedding_layer), (ag__.ld(hidden_states),), None, fscope)\n    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n        embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'tf_segformer_for_semantic_segmentation' (type TFSegformerForSemanticSegmentation).\n    \n    in user code:\n    \n        File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 792, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 819, in call  *\n            outputs = self.segformer(\n        File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py\", line 40, in tf__run_call_with_unpacked_inputs\n            raise\n        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filek7eal_6g.py\", line 15, in tf__call\n            encoder_outputs = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(pixel_values),), dict(output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 103, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.converted_call(ag__.ld(zip), (ag__.ld(self).embeddings, ag__.ld(self).block, ag__.ld(self).layer_norms), None, fscope),), None, fscope), None, loop_body_1, get_state_4, set_state_4, ('all_hidden_states', 'all_self_attentions', 'hidden_states'), {'iterate_names': '(idx, x)'})\n        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 27, in loop_body_1\n            hidden_states, height, width = ag__.converted_call(ag__.ld(embedding_layer), (ag__.ld(hidden_states),), None, fscope)\n        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n            embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'segformer' (type TFSegformerMainLayer).\n        \n        in user code:\n        \n            File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 792, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 484, in call  *\n                encoder_outputs = self.encoder(\n            File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 103, in tf__call\n                ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.converted_call(ag__.ld(zip), (ag__.ld(self).embeddings, ag__.ld(self).block, ag__.ld(self).layer_norms), None, fscope),), None, fscope), None, loop_body_1, get_state_4, set_state_4, ('all_hidden_states', 'all_self_attentions', 'hidden_states'), {'iterate_names': '(idx, x)'})\n            File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 27, in loop_body_1\n                hidden_states, height, width = ag__.converted_call(ag__.ld(embedding_layer), (ag__.ld(hidden_states),), None, fscope)\n            File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n                embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n        \n            ValueError: Exception encountered when calling layer 'encoder' (type TFSegformerEncoder).\n            \n            in user code:\n            \n                File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 419, in call  *\n                    hidden_states, height, width = embedding_layer(hidden_states)\n                File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n                    embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n            \n                ValueError: Exception encountered when calling layer 'patch_embeddings.0' (type TFSegformerOverlapPatchEmbeddings).\n                \n                in user code:\n                \n                    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 92, in call  *\n                        embeddings = self.proj(self.padding(pixel_values))\n                    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                        raise e.with_traceback(filtered_tb) from None\n                    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n                        raise ValueError(\n                \n                    ValueError: Input 0 of layer \"proj\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 262, 9, 256)\n                \n                \n                Call arguments received by layer 'patch_embeddings.0' (type TFSegformerOverlapPatchEmbeddings):\n                   pixel_values=tf.Tensor(shape=(None, 256, 3, 256), dtype=float32)\n            \n            \n            Call arguments received by layer 'encoder' (type TFSegformerEncoder):\n               pixel_values=tf.Tensor(shape=(None, 256, 3, 256), dtype=float32)\n               output_attentions=False\n               output_hidden_states=True\n               return_dict=True\n               training=True\n        \n        \n        Call arguments received by layer 'segformer' (type TFSegformerMainLayer):\n           pixel_values=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)\n           output_attentions=False\n           output_hidden_states=True\n           return_dict=True\n           training=True\n    \n    \n    Call arguments received by layer 'tf_segformer_for_semantic_segmentation' (type TFSegformerForSemanticSegmentation):\n       pixel_values={'pixel_values': 'tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)', 'labels': 'tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)'}\n       labels=None\n       output_attentions=None\n       output_hidden_states=None\n       return_dict=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n",
      "\u001b[1;32m      2\u001b[0m     train_ds,\n",
      "\u001b[1;32m      3\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_ds,\n",
      "\u001b[1;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n",
      "\u001b[1;32m      5\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n",
      "\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n",
      "\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_file3nq5o0qg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n",
      "\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1642\u001b[0m, in \u001b[0;36mTFPreTrainedModel.train_step\u001b[0;34m(self, data)\u001b[0m\n",
      "\u001b[1;32m   1640\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_loss\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m   1641\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1642\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m   1643\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_using_dummy_loss:\n",
      "\u001b[1;32m   1644\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(y_pred\u001b[39m.\u001b[39mloss, y_pred\u001b[39m.\u001b[39mloss, sample_weight, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m     36\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(func), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m),), \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mag__\u001b[39m.\u001b[39mld(unpacked_inputs)), fscope)\n",
      "\u001b[1;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;32m     39\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filekaed2bas.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, pixel_values, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[1;32m     39\u001b[0m return_dict \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mif_exp(ag__\u001b[39m.\u001b[39mld(return_dict) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(return_dict), \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict, \u001b[39m'\u001b[39m\u001b[39mreturn_dict is not None\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m     40\u001b[0m output_hidden_states \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mif_exp(ag__\u001b[39m.\u001b[39mld(output_hidden_states) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(output_hidden_states), \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moutput_hidden_states, \u001b[39m'\u001b[39m\u001b[39moutput_hidden_states is not None\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;32m---> 41\u001b[0m outputs \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49msegformer, (ag__\u001b[39m.\u001b[39;49mld(pixel_values),), \u001b[39mdict\u001b[39;49m(output_attentions\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(output_attentions), output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_dict\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(return_dict)), fscope)\n",
      "\u001b[1;32m     42\u001b[0m encoder_hidden_states \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mif_exp(ag__\u001b[39m.\u001b[39mld(return_dict), \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(outputs)\u001b[39m.\u001b[39mhidden_states, \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(outputs)[\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m     43\u001b[0m logits \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecode_head, (ag__\u001b[39m.\u001b[39mld(encoder_hidden_states),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m     36\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(func), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m),), \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mag__\u001b[39m.\u001b[39mld(unpacked_inputs)), fscope)\n",
      "\u001b[1;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;32m     39\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filek7eal_6g.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n",
      "\u001b[1;32m     13\u001b[0m return_dict \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mif_exp(ag__\u001b[39m.\u001b[39mld(return_dict) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(return_dict), \u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict, \u001b[39m'\u001b[39m\u001b[39mreturn_dict is not None\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m     14\u001b[0m pixel_values \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mtranspose, (ag__\u001b[39m.\u001b[39mld(pixel_values),), \u001b[39mdict\u001b[39m(perm\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)), fscope)\n",
      "\u001b[0;32m---> 15\u001b[0m encoder_outputs \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mencoder, (ag__\u001b[39m.\u001b[39;49mld(pixel_values),), \u001b[39mdict\u001b[39;49m(output_attentions\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(output_attentions), output_hidden_states\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(output_hidden_states), return_dict\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(return_dict), training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training)), fscope)\n",
      "\u001b[1;32m     16\u001b[0m sequence_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(encoder_outputs)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m     17\u001b[0m sequence_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mtranspose, (ag__\u001b[39m.\u001b[39mld(sequence_output),), \u001b[39mdict\u001b[39m(perm\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]), fscope)\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py:103\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n",
      "\u001b[1;32m    101\u001b[0m i \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m    102\u001b[0m blk \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mblk\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;32m--> 103\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39menumerate\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mzip\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49membeddings, ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mblock, ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlayer_norms), \u001b[39mNone\u001b[39;49;00m, fscope),), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39mNone\u001b[39;49;00m, loop_body_1, get_state_4, set_state_4, (\u001b[39m'\u001b[39;49m\u001b[39mall_hidden_states\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mall_self_attentions\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mhidden_states\u001b[39;49m\u001b[39m'\u001b[39;49m), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m(idx, x)\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_5\u001b[39m():\n",
      "\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m (do_return, retval_)\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py:27\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body_1\u001b[0;34m(itr_1)\u001b[0m\n",
      "\u001b[1;32m     25\u001b[0m idx, x \u001b[39m=\u001b[39m itr_1\n",
      "\u001b[1;32m     26\u001b[0m embedding_layer, block_layer, norm_layer \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(x)\n",
      "\u001b[0;32m---> 27\u001b[0m hidden_states, height, width \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(embedding_layer), (ag__\u001b[39m.\u001b[39;49mld(hidden_states),), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_1\u001b[39m():\n",
      "\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m (all_self_attentions, hidden_states)\n",
      "\n",
      "File \u001b[0;32m/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, pixel_values)\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32m     10\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n",
      "\u001b[0;32m---> 11\u001b[0m embeddings \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mproj, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mpadding, (ag__\u001b[39m.\u001b[39;49mld(pixel_values),), \u001b[39mNone\u001b[39;49;00m, fscope),), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "\u001b[1;32m     12\u001b[0m height \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(shape_list), (ag__\u001b[39m.\u001b[39mld(embeddings),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;32m     13\u001b[0m width \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(shape_list), (ag__\u001b[39m.\u001b[39mld(embeddings),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m2\u001b[39m]\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n",
      "\n",
      "    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1642, in train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py\", line 40, in tf__run_call_with_unpacked_inputs\n",
      "        raise\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filekaed2bas.py\", line 41, in tf__call\n",
      "        outputs = ag__.converted_call(ag__.ld(self).segformer, (ag__.ld(pixel_values),), dict(output_attentions=ag__.ld(output_attentions), output_hidden_states=True, return_dict=ag__.ld(return_dict)), fscope)\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py\", line 40, in tf__run_call_with_unpacked_inputs\n",
      "        raise\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filek7eal_6g.py\", line 15, in tf__call\n",
      "        encoder_outputs = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(pixel_values),), dict(output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 103, in tf__call\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.converted_call(ag__.ld(zip), (ag__.ld(self).embeddings, ag__.ld(self).block, ag__.ld(self).layer_norms), None, fscope),), None, fscope), None, loop_body_1, get_state_4, set_state_4, ('all_hidden_states', 'all_self_attentions', 'hidden_states'), {'iterate_names': '(idx, x)'})\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 27, in loop_body_1\n",
      "        hidden_states, height, width = ag__.converted_call(ag__.ld(embedding_layer), (ag__.ld(hidden_states),), None, fscope)\n",
      "    File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n",
      "        embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n",
      "\n",
      "    ValueError: Exception encountered when calling layer 'tf_segformer_for_semantic_segmentation' (type TFSegformerForSemanticSegmentation).\n",
      "    \n",
      "    in user code:\n",
      "    \n",
      "        File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 792, in run_call_with_unpacked_inputs  *\n",
      "            return func(self, **unpacked_inputs)\n",
      "        File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 819, in call  *\n",
      "            outputs = self.segformer(\n",
      "        File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n",
      "            raise e.with_traceback(filtered_tb) from None\n",
      "        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filetww8ogrs.py\", line 40, in tf__run_call_with_unpacked_inputs\n",
      "            raise\n",
      "        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filek7eal_6g.py\", line 15, in tf__call\n",
      "            encoder_outputs = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(pixel_values),), dict(output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n",
      "        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 103, in tf__call\n",
      "            ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.converted_call(ag__.ld(zip), (ag__.ld(self).embeddings, ag__.ld(self).block, ag__.ld(self).layer_norms), None, fscope),), None, fscope), None, loop_body_1, get_state_4, set_state_4, ('all_hidden_states', 'all_self_attentions', 'hidden_states'), {'iterate_names': '(idx, x)'})\n",
      "        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 27, in loop_body_1\n",
      "            hidden_states, height, width = ag__.converted_call(ag__.ld(embedding_layer), (ag__.ld(hidden_states),), None, fscope)\n",
      "        File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n",
      "            embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n",
      "    \n",
      "        ValueError: Exception encountered when calling layer 'segformer' (type TFSegformerMainLayer).\n",
      "        \n",
      "        in user code:\n",
      "        \n",
      "            File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 792, in run_call_with_unpacked_inputs  *\n",
      "                return func(self, **unpacked_inputs)\n",
      "            File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 484, in call  *\n",
      "                encoder_outputs = self.encoder(\n",
      "            File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n",
      "                raise e.with_traceback(filtered_tb) from None\n",
      "            File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 103, in tf__call\n",
      "                ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.converted_call(ag__.ld(zip), (ag__.ld(self).embeddings, ag__.ld(self).block, ag__.ld(self).layer_norms), None, fscope),), None, fscope), None, loop_body_1, get_state_4, set_state_4, ('all_hidden_states', 'all_self_attentions', 'hidden_states'), {'iterate_names': '(idx, x)'})\n",
      "            File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filenmzuttna.py\", line 27, in loop_body_1\n",
      "                hidden_states, height, width = ag__.converted_call(ag__.ld(embedding_layer), (ag__.ld(hidden_states),), None, fscope)\n",
      "            File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n",
      "                embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n",
      "        \n",
      "            ValueError: Exception encountered when calling layer 'encoder' (type TFSegformerEncoder).\n",
      "            \n",
      "            in user code:\n",
      "            \n",
      "                File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 419, in call  *\n",
      "                    hidden_states, height, width = embedding_layer(hidden_states)\n",
      "                File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n",
      "                    raise e.with_traceback(filtered_tb) from None\n",
      "                File \"/var/folders/hl/hfkbp3_54j7g9499gz2266zw0000gn/T/__autograph_generated_filej1e99pql.py\", line 11, in tf__call\n",
      "                    embeddings = ag__.converted_call(ag__.ld(self).proj, (ag__.converted_call(ag__.ld(self).padding, (ag__.ld(pixel_values),), None, fscope),), None, fscope)\n",
      "            \n",
      "                ValueError: Exception encountered when calling layer 'patch_embeddings.0' (type TFSegformerOverlapPatchEmbeddings).\n",
      "                \n",
      "                in user code:\n",
      "                \n",
      "                    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/transformers/models/segformer/modeling_tf_segformer.py\", line 92, in call  *\n",
      "                        embeddings = self.proj(self.padding(pixel_values))\n",
      "                    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n",
      "                        raise e.with_traceback(filtered_tb) from None\n",
      "                    File \"/Users/sevincjakab/neuefische_bootcamp/20230717-NewRepo-Capstone-Building_Damage/Capstone_Building_Damage/.venv/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n",
      "                        raise ValueError(\n",
      "                \n",
      "                    ValueError: Input 0 of layer \"proj\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 262, 9, 256)\n",
      "                \n",
      "                \n",
      "                Call arguments received by layer 'patch_embeddings.0' (type TFSegformerOverlapPatchEmbeddings):\n",
      "                   pixel_values=tf.Tensor(shape=(None, 256, 3, 256), dtype=float32)\n",
      "            \n",
      "            \n",
      "            Call arguments received by layer 'encoder' (type TFSegformerEncoder):\n",
      "               pixel_values=tf.Tensor(shape=(None, 256, 3, 256), dtype=float32)\n",
      "               output_attentions=False\n",
      "               output_hidden_states=True\n",
      "               return_dict=True\n",
      "               training=True\n",
      "        \n",
      "        \n",
      "        Call arguments received by layer 'segformer' (type TFSegformerMainLayer):\n",
      "           pixel_values=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)\n",
      "           output_attentions=False\n",
      "           output_hidden_states=True\n",
      "           return_dict=True\n",
      "           training=True\n",
      "    \n",
      "    \n",
      "    Call arguments received by layer 'tf_segformer_for_semantic_segmentation' (type TFSegformerForSemanticSegmentation):\n",
      "       pixel_values={'pixel_values': 'tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)', 'labels': 'tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)'}\n",
      "       labels=None\n",
      "       output_attentions=None\n",
      "       output_hidden_states=None\n",
      "       return_dict=None\n"
     ]
    }
   ],
   "source": [
    "# error!\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
