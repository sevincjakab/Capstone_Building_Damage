{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Description***\n",
    "\n",
    "This script uses pair of png satellite images (pre- and post-disaster) and corresponding json files with labels pre-disaster (building polygons) and post-disaster (damage level) \n",
    "to create 4 tensors: \n",
    "\n",
    "1. pre-image tensor (height,width,3)\n",
    "2. segmentation mask tensor (height,width,1)\n",
    "3. post-image tensor (height,width,3)\n",
    "4. classification mask tensor (height,width,1)\n",
    "\n",
    "1 and 2 are saved in file --> tensors_pre_[database].npz (useful for segmentation)\n",
    "3 and 4 are saved in file --> tensors_post_[database].npz (useful for classification)\n",
    "\n",
    ", with [database] the name of the database being used (see variable \"database_dir\" at the end of this file)\n",
    "\n",
    "Labels for damage classification (used to create tensor n°4)\n",
    "\n",
    "Class 0 - no building or un-classified building\n",
    "\n",
    "Class 1 - no-damage\n",
    "\n",
    "Class 2 - minor damage\n",
    "\n",
    "Class 3 - major damage\n",
    "\n",
    "Class 4 - destroyed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data need to be in the following format. To create this structure, use **split_into_disasters.py** from __[xView2 baseline](https://github.com/DIUx-xView/xView2_baseline/tree/master)__ :\n",
    "\n",
    "\n",
    " folder with the data base: \n",
    "\n",
    "├── disaster_name_1\n",
    "\n",
    " │------├── images \n",
    "\n",
    " │------│------------<image_id>.png\n",
    "\n",
    " │------│------------...\n",
    "\n",
    " │------├── labels\n",
    "\n",
    " │------│------------<image_id>.json\n",
    "\n",
    " │------│------------...\n",
    "\n",
    "├── disaster_name_2\n",
    "\n",
    " │------├── images \n",
    "\n",
    " │------│------------<image_id>.png\n",
    "\n",
    " │------│------------...\n",
    "\n",
    " │------├── labels\n",
    "\n",
    " │------│------------<image_id>.json\n",
    "\n",
    " │------│------------...\n",
    "\n",
    "└── disaster_name_n\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The script includes and/or makes use of functions created during the xView2 challenge set by DIU (Defense Innovation Unit) through their baseline repository: xView2_baseline.**\n",
    "\n",
    "__[xView2 license](https://github.com/DIUx-xView/xView2_baseline/blob/master/LICENSE.md)__   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gmeneses/DScourse/00_capstone/Capstone_Building_Damage/notebooks/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from os import path, walk, makedirs\n",
    "from sys import exit, stderr\n",
    "\n",
    "from cv2 import fillPoly, imwrite\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from shapely.geometry import mapping, Polygon\n",
    "from skimage.io import imread\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# This removes the massive amount of scikit warnings of \"low contrast images\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from XView2 baseline\n",
    "def get_dimensions(file_path):\n",
    "    \"\"\"\n",
    "    :param file_path: The path of the file \n",
    "    :return: returns (width,height,channels)\n",
    "    \"\"\"\n",
    "    # Open the image we are going to mask\n",
    "    pil_img = imread(file_path)\n",
    "    img = np.array(pil_img)\n",
    "    w, h, c = img.shape\n",
    "    return (w, h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xView2 baseline\n",
    "def save_one_mask(masks, output_path, mask_file_name):\n",
    "    \"\"\"\n",
    "    :param masks: list of masked polygons from the mask_polygons_separately function \n",
    "    :param output_path: path to save the masks\n",
    "    :param mask_file_name: the file name the masks should have \n",
    "    \"\"\"\n",
    "    # For each filled polygon, write the mask shape out to the file per image\n",
    "    mask_file_name = path.join(output_path, mask_file_name + '.png')\n",
    "    imwrite(mask_file_name, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from xView2 baseline \n",
    "def mask_polygons_together_with_border(size, shapes_pre, shapes_post, border):\n",
    "    \"\"\"\n",
    "    :param size: A tuple of the (width,height,channels)\n",
    "    :param shape_pre: A list of points in the polygon from get_feature_info\n",
    "    :param shape_post: A list of damage level labels from get_feature_damage\n",
    "    :param border: number of pixels used to shrink the polygon in the case that there is building overlapping\n",
    "\n",
    "    :returns: an array with the size of the original images, with pixel-wise labels including \n",
    "    building and damage information.\n",
    "    \"\"\"\n",
    "\n",
    "    # For each WKT polygon, read the WKT format and fill the polygon as an image\n",
    "    mask_img_buildings = np.zeros(size, np.uint8)\n",
    "    mask_img_damage = np.zeros(size, np.uint8)\n",
    "    \n",
    "    \n",
    "\n",
    "    for u in shapes_pre:\n",
    "        #defining 2 arrays (one for building location, the next for damage level information)\n",
    "        blank_building =  np.zeros(size, np.uint8)\n",
    "        blank_damage =  np.zeros(size, np.uint8)\n",
    "\n",
    "        # Each polygon stored in shapes is a np.ndarray\n",
    "        poly = shapes_pre[u]\n",
    "        # the damage label for this particular building\n",
    "        dam = shapes_post[u]\n",
    "        # Creating a shapely polygon object out of the numpy array \n",
    "        polygon = Polygon(poly)\n",
    "        \n",
    "        # Getting the center points from the polygon and the polygon points\n",
    "        (poly_center_x, poly_center_y) = polygon.centroid.coords[0]\n",
    "        polygon_points = polygon.exterior.coords\n",
    "\n",
    "        # Setting a new polygon with each X,Y manipulated based off the center point\n",
    "        shrunk_polygon = []\n",
    "        for (x,y) in polygon_points:\n",
    "            if x < poly_center_x:\n",
    "                x += border\n",
    "            elif x > poly_center_x:\n",
    "                x -= border\n",
    "\n",
    "            if y < poly_center_y:\n",
    "                y += border\n",
    "            elif y > poly_center_y:\n",
    "                y -= border\n",
    "\n",
    "            shrunk_polygon.append([x,y])\n",
    "        \n",
    "        # Transforming the polygon back to a np.ndarray\n",
    "        ns_poly = np.array(shrunk_polygon, np.int32)\n",
    "        \n",
    "        # depending on level of damage the color (uses a dictionary defined at the top)\n",
    "        if dam == \"no-damage\":\n",
    "            color = 1\n",
    "        elif dam == \"minor-damage\":\n",
    "            color = 2\n",
    "        elif dam == \"major-damage\":\n",
    "            color = 3\n",
    "        elif dam == \"destroyed\":           \n",
    "            color = 4\n",
    "        else: # includes 2 cases: no building and un-classified buildings\n",
    "            color = 0\n",
    "            #print(\"This building has unknown damage class: \"+u)     \n",
    "        \n",
    "        # Filling the shrunken polygon to add a border between close polygons\n",
    "        fillPoly(blank_building, [ns_poly], 1)\n",
    "        fillPoly(blank_damage, [ns_poly], color)\n",
    "        # updating labels for eack iteration (= building)\n",
    "        mask_img_buildings += blank_building\n",
    "        mask_img_damage += blank_damage\n",
    "\n",
    "\n",
    "    #print(np.count_nonzero(mask_img_damage.flatten()))\n",
    "    # solving the problem of overlapping buildings --> zeros will be in the pixels where\n",
    "    #there is no building and where buildings overlapped (pixels with values > 1)\n",
    "    mask_img_buildings[mask_img_buildings > 1] = 0\n",
    "    mask_img_buildings[mask_img_buildings == 1] = 1\n",
    "    # multiplying the damage array and the previous array will leave values only where there are ones\n",
    "    final_mask = mask_img_buildings * mask_img_damage\n",
    "    return mask_img_buildings,final_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from XView2 baseline\n",
    "def read_json(json_path):\n",
    "    \"\"\"\n",
    "    :param json_path: path to load json from\n",
    "    :returns: a python dictionary of json features\n",
    "    \"\"\"\n",
    "    annotations = json.load(open(json_path))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from XView2 baseline\n",
    "def get_feature_info(feature):\n",
    "    \"\"\"\n",
    "    :param feature: a python dictionary of json labels\n",
    "    :returns: a list mapping of polygons contained in the image \n",
    "    \"\"\"\n",
    "    # Getting each polygon points from the json file and adding it to a dictionary of uid:polygons\n",
    "    props = {}\n",
    "\n",
    "    for feat in feature['features']['xy']:\n",
    "        feat_shape = wkt.loads(feat['wkt'])\n",
    "        coords = list(mapping(feat_shape)['coordinates'][0])\n",
    "        props[feat['properties']['uid']] = (np.array(coords, np.int32))\n",
    "\n",
    "    return props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_damage(feature):\n",
    "    \"\"\"\n",
    "    Creates a dictionary with the damage labels by building. Uses the same key that props dict.\n",
    "    :param feature: a python dictionary of json labels (post-disaster with damage labels)\n",
    "    :returns: a list of damage labels contained in the image \n",
    "    \n",
    "    \"\"\"\n",
    "    damage = {}\n",
    "\n",
    "    for feat in feature['features']['xy']:\n",
    "        try:\n",
    "            damage_type = feat['properties']['subtype']\n",
    "        except: # pre-disaster damage is default no-damage\n",
    "            damage_type = \"no-damage\"\n",
    "            print(\"no damage info in \"+feat['properties']['uid'])\n",
    "            continue  \n",
    "        damage[feat['properties']['uid']] = damage_type\n",
    "\n",
    "    return damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disaster_info(feature):\n",
    "    \"\"\"\n",
    "    Creates 2 lists with disaster name and disaster type\n",
    "    :param feature: a python dictionary of json labels ( pre- or post-disaster)\n",
    "    :returns: 2 lists with length = n pre_images = n post_images\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    try:\n",
    "        disaster = feature['metadata']['disaster']\n",
    "        disaster_type = feature['metadata']['disaster_type']\n",
    "    except:\n",
    "        disaster = 'unclassified'\n",
    "        disaster_type = 'unclassified'\n",
    "        print(\"no disaster information in \"+feature['metadata']['img_name'])\n",
    "         \n",
    "\n",
    "    return disaster,disaster_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from XView2 baseline. Now includes information of the post-damage files and create tensors for images and masks\n",
    "\n",
    "def create_masks(json_path, images_directory):\n",
    "    '''\n",
    "    Creates pre- and post-tensors (images, masks, id's, disaster name, disaster type )\n",
    "    :param json_path: path to json labels ( pre- and post-disaster)\n",
    "    :param images_directory: path to images ( pre- and post-disaster)\n",
    "\n",
    "    :returns: 6 tensors (pre and post)\n",
    "    '''\n",
    "    arr_img_pre_list = []\n",
    "    arr_img_post_list = []\n",
    "    lm1 = []\n",
    "    lm2 = []\n",
    "    id_pre_list = []\n",
    "    id_post_list = []\n",
    "    dis_list = []\n",
    "    dis_type_list = []\n",
    "\n",
    "    # For each feature in the json we will create a separate mask\n",
    "    # Getting all files in the directory provided for jsons\n",
    "    jsons_pre = [j for j in next(walk(json_path))[2] if '_pre' in j]\n",
    "    # After removing non-json items in dir (if any)\n",
    "    for j in tqdm([j for j in jsons_pre if j.endswith('json')],\n",
    "                  unit='poly',\n",
    "                  leave=False):\n",
    "        # Our chips start off in life as PNGs\n",
    "        chip_image_id_pre = path.splitext(j)[0] + '.png'\n",
    "        chip_image_id_post = path.splitext(j)[0].replace('_pre', '_post') + '.png'\n",
    "\n",
    "        id_pre = path.splitext(j)[0]\n",
    "        id_post = path.splitext(j)[0].replace('_pre', '_post')\n",
    "\n",
    "        # Loading the per chip json pre-disaster\n",
    "        j_full_path_pre = path.join(json_path, j)\n",
    "        chip_json_pre = read_json(j_full_path_pre)\n",
    "        \n",
    "        #getting the name of the post-json\n",
    "        j_post = j.replace('_pre', '_post')\n",
    "        #print(j_post)\n",
    "        \n",
    "        # Loading the per chip json post-disaster\n",
    "        j_full_path_post = path.join(json_path, j_post)\n",
    "        chip_json_post = read_json(j_full_path_post)\n",
    "\n",
    "        # Getting the full chip path, and loading the size dimensions (same for post)\n",
    "        chip_file_pre = path.join(images_directory, chip_image_id_pre)\n",
    "        chip_file_post = path.join(images_directory, chip_image_id_post)\n",
    "\n",
    "        chip_img_size = get_dimensions(chip_file_pre)\n",
    "        chip_size = (chip_img_size[0],chip_img_size[0],1)\n",
    "        # Reading in the polygons from the json file\n",
    "        polys_pre = get_feature_info(chip_json_pre)\n",
    "        polys_post = get_feature_damage(chip_json_post)\n",
    "\n",
    "        # Getting a list of the polygons and saving masks as separate or single image files\n",
    "        if len(polys_pre) > 0:\n",
    "            m1,m2 = mask_polygons_together_with_border(chip_size, polys_pre, polys_post, 2)\n",
    "            lm1.append(m1)\n",
    "            lm2.append(m2)\n",
    "            # creating tensors from images\n",
    "            img_pre = tf.io.read_file(chip_file_pre)\n",
    "            img_post = tf.io.read_file(chip_file_post)\n",
    "            array_pre = tf.image.decode_png(img_pre, channels=3, dtype=tf.uint8)\n",
    "            array_post = tf.image.decode_png(img_post, channels=3, dtype=tf.uint8)\n",
    "            \n",
    "            dis,dis_type = get_disaster_info(chip_json_pre)\n",
    "            \n",
    "            arr_img_pre_list.append(array_pre)\n",
    "            arr_img_post_list.append(array_post)\n",
    "            #creating id and id_disaster lists to identify the arrays\n",
    "            id_pre_list.append(id_pre)\n",
    "            id_post_list.append(id_post)\n",
    "            dis_list.append(dis)\n",
    "            dis_type_list.append(dis_type)\n",
    "\n",
    "            #save_one_mask(masked_polys, output_directory, mask_file)\n",
    "    return arr_img_pre_list, arr_img_post_list, lm1,lm2,id_pre_list,id_post_list,dis_list,dis_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "# DATABASE_DIR IS A FOLDER THAT CONTAINS THE DATA DIVIDED BY DISASTERS, IN EACH DISASTER FOLDER THERE ARE \"IMAGES\" (PNG FILES) AND \"LABELS\" FOLDERS (JSON FILES).\n",
    "\n",
    "# Modified from XView2 baseline\n",
    "database_dir = '../data/data_by_disaster'\n",
    "#give an identifier string to add to npz files name\n",
    "database = 'test'\n",
    "\n",
    "# Getting the list of the disaster types under the xBD directory\n",
    "disasters = next(walk(database_dir))[1]\n",
    "final_list_imgpre = []\n",
    "final_list_imgpost = []\n",
    "final_list_maskseg = []\n",
    "final_list_maskclas = []\n",
    "id_all_pre = []\n",
    "id_all_post = []\n",
    "dis_all = []\n",
    "dis_type_all = []\n",
    "\n",
    "\n",
    "for disaster in disasters:\n",
    "    if \"-\" in disaster:\n",
    "        # Create the full path to the images, labels, and mask output directories\n",
    "        image_dir = path.join(database_dir, disaster, 'images')\n",
    "        json_dir = path.join(database_dir, disaster, 'labels')\n",
    "\n",
    "        if not path.isdir(image_dir):\n",
    "            print(\n",
    "                \"Error, could not find image files in {}.\\n\\n\"\n",
    "                .format(image_dir),\n",
    "                file=stderr)\n",
    "            exit(2)\n",
    "\n",
    "        if not path.isdir(json_dir):\n",
    "            print(\n",
    "                \"Error, could not find labels in {}.\\n\\n\"\n",
    "                .format(json_dir),\n",
    "                file=stderr)\n",
    "            exit(3)\n",
    "        \n",
    "        #print([j for j in next(walk(json_dir))[2] if '_pre' in j]    )\n",
    "        #print(json_dir, image_dir, output_dir)\n",
    "        l1,l2,l3,l4,id1,id2,dis,dis_type = create_masks(json_dir, image_dir)\n",
    "        final_list_imgpre.extend(l1)\n",
    "        final_list_imgpost.extend(l2)\n",
    "        final_list_maskseg.extend(l3)\n",
    "        final_list_maskclas.extend(l4)\n",
    "        id_all_pre.extend(id1)\n",
    "        id_all_post.extend(id2)\n",
    "        dis_all.extend(dis)\n",
    "        dis_type_all.extend(dis_type)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images_pre = np.stack(final_list_imgpre)\n",
    "images_post = np.stack(final_list_imgpost)\n",
    "\n",
    "masks_pre = np.stack(final_list_maskseg)\n",
    "masks_post = np.stack(final_list_maskclas)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the arrays in npz numpy format\n",
    " \n",
    "np.savez('tensors_pre_'+database+'.npz', images=images_pre, masks=masks_pre, id=id_all_pre, disaster_name=dis_all, disaster_type=dis_type_all)\n",
    "np.savez('tensors_post_'+database+'.npz', images=images_post, masks=masks_post, id=id_all_post, disaster_name=dis_all, disaster_type=dis_type_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
